{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836cbd56-571b-47bd-8f27-7da955ffeded",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting \n",
    "(for NO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7df3e0fb-e48a-44aa-be37-1fd4be83f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.12/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa58e9a1-f4e6-4962-aa48-a4f044b3aff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge xgboost -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d088983d-b78c-478f-a9fa-873bd124d626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model for Chicago\n",
      "Chicago Model Performance:\n",
      "   • Mean Absolute Error (MAE): 3.1177\n",
      "   • Mean Squared Error (MSE): 17.5033\n",
      "   • R-squared Score (R²): 0.7164\n",
      "\n",
      "Training Model for Los Angeles\n",
      "Los Angeles Model Performance:\n",
      "   • Mean Absolute Error (MAE): 6.5823\n",
      "   • Mean Squared Error (MSE): 70.5231\n",
      "   • R-squared Score (R²): 0.4636\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"/Users/shrutikute/Downloads/updated_air_quality_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Map county names to city names\n",
    "county_to_city = {\n",
    "    \"Cook\": \"Chicago\",\n",
    "    \"Los Angeles\": \"Los Angeles\"\n",
    "}\n",
    "\n",
    "df[\"City\"] = df[\"County Name\"].map(county_to_city)  # Create a 'City' column\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['temperature_2m (°C)', 'relative_humidity_2m (%)', \n",
    "            'precipitation (mm)', 'wind_speed_100m (km/h)', 'Day', 'Hour']\n",
    "target = 'NO2'  # Updating the target variable to NO2\n",
    "\n",
    "# Drop rows with missing target values\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Loop through each city (Chicago, Los Angeles) and train a model\n",
    "for city in [\"Chicago\", \"Los Angeles\"]:\n",
    "    print(f\"\\nTraining Model for {city}\")\n",
    "    \n",
    "    # Filter data for the specific city\n",
    "    city_df = df[df[\"City\"] == city]\n",
    "    \n",
    "    # Check if there's enough data\n",
    "    if city_df.shape[0] < 50:  # Adjust threshold as needed\n",
    "        print(f\"Not enough data for {city}. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Extract features and target\n",
    "    X = city_df[features]\n",
    "    y = city_df[target]\n",
    "\n",
    "    # Standardizing features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data into training (80%) and testing (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train XGBoost model with optimized hyperparameters\n",
    "    xgb_regressor = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror', \n",
    "        n_estimators=500, \n",
    "        learning_rate=0.05, \n",
    "        max_depth=8, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{city} Model Performance:\")\n",
    "    print(f\"   • Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"   • Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"   • R-squared Score (R²): {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b104cbb-66a4-4e45-a59a-e451481952a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model for Chicago\n",
      "Best Hyperparameters for Chicago: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 300, 'reg_alpha': 0.01, 'reg_lambda': 50, 'subsample': 0.8}\n",
      "Chicago Model Performance:\n",
      "   • Mean Absolute Error (MAE): 1.7118\n",
      "   • Mean Squared Error (MSE): 6.0558\n",
      "   • R-squared Score (R²): 0.9019\n",
      "\n",
      "Training Model for Los Angeles\n",
      "Best Hyperparameters for Los Angeles: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 300, 'reg_alpha': 0.1, 'reg_lambda': 50, 'subsample': 0.8}\n",
      "Los Angeles Model Performance:\n",
      "   • Mean Absolute Error (MAE): 2.3266\n",
      "   • Mean Squared Error (MSE): 11.2268\n",
      "   • R-squared Score (R²): 0.9146\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"/Users/shrutikute/Downloads/updated_air_quality_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Fix column names to remove whitespace\n",
    "df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "# Map County Names to City Names (only for Chicago & LA)\n",
    "county_to_city = {\n",
    "    \"Cook\": \"Chicago\",\n",
    "    \"Los Angeles\": \"Los Angeles\"\n",
    "}\n",
    "df[\"City\"] = df[\"County_Name\"].map(county_to_city)\n",
    "\n",
    "# Feature Engineering - Convert 'Day' to Cyclic Encoding\n",
    "df['Day_sin'] = np.sin(2 * np.pi * df['Day'] / 7)\n",
    "df['Day_cos'] = np.cos(2 * np.pi * df['Day'] / 7)\n",
    "\n",
    "# Feature Engineering - Rolling Average for NO2 (3-hour trend)\n",
    "df[\"NO2_Rolling_Avg\"] = df[\"NO2\"].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "# Define updated features\n",
    "features = [\n",
    "    'temperature_2m_(°C)', 'relative_humidity_2m_(%)', \n",
    "    'precipitation_(mm)', 'wind_speed_100m_(km/h)',\n",
    "    'Day_sin', 'Day_cos', 'NO2_Rolling_Avg', 'Hour'\n",
    "]\n",
    "target = 'NO2'  # Updating the target variable to NO2\n",
    "\n",
    "# Drop rows with missing values in features and target\n",
    "df = df.dropna(subset=features + [target])\n",
    "\n",
    "# Loop through each city (Chicago, Los Angeles) and train a model\n",
    "for city in [\"Chicago\", \"Los Angeles\"]:\n",
    "    print(f\"\\nTraining Model for {city}\")\n",
    "    \n",
    "    # Filter data for the specific city\n",
    "    city_df = df[df[\"City\"] == city]\n",
    "    \n",
    "    # Check if there's enough data\n",
    "    if city_df.shape[0] < 50:\n",
    "        print(f\"Not enough data for {city}. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Extract features and target\n",
    "    X = city_df[features]\n",
    "    y = city_df[target]\n",
    "\n",
    "    # Standardizing features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split data into training (80%) and testing (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define parameter grid for Grid Search\n",
    "    param_grid = {\n",
    "        'n_estimators': [300, 500],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [6, 8],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'reg_alpha': [0.01, 0.1],  # L1 Regularization\n",
    "        'reg_lambda': [1, 10, 50]  # L2 Regularization\n",
    "    }\n",
    "\n",
    "    # Initialize XGBoost model\n",
    "    xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "    # Perform Grid Search CV\n",
    "    tuner = GridSearchCV(\n",
    "        xgb_regressor, param_grid, scoring='r2', cv=3, verbose=0, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    tuner.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters\n",
    "    best_params = tuner.best_params_\n",
    "    print(f\"Best Hyperparameters for {city}: {best_params}\")\n",
    "\n",
    "    # Train model with best parameters found through grid search\n",
    "    xgb_best = xgb.XGBRegressor(**best_params, objective='reg:squarederror', random_state=42)\n",
    "    xgb_best.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb_best.predict(X_test)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{city} Model Performance:\")\n",
    "    print(f\"   • Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"   • Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"   • R-squared Score (R²): {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9132cf-f35f-47ff-b340-d71715c5bcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
